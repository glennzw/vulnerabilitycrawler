commit 83e0bbcbe2145f160fbaa109b0439dae7f4a38a9
Author: Alan Cox <alan@lxorguk.ukuu.org.uk>
Date:   Fri Mar 27 00:28:21 2009 -0700

    af_rose/x25: Sanity check the maximum user frame size
    
    Otherwise we can wrap the sizes and end up sending garbage.
    
    Closes #10423
    
    Signed-off-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/net/netrom/af_netrom.c b/net/netrom/af_netrom.c
index 6d9c58e..d1c16bb 100644
--- a/net/netrom/af_netrom.c
+++ b/net/netrom/af_netrom.c
@@ -1028,112 +1028,116 @@ int nr_rx_frame(struct sk_buff *skb, struct net_device *dev)
 static int nr_sendmsg(struct kiocb *iocb, struct socket *sock,
 		      struct msghdr *msg, size_t len)
 {
 	struct sock *sk = sock->sk;
 	struct nr_sock *nr = nr_sk(sk);
 	struct sockaddr_ax25 *usax = (struct sockaddr_ax25 *)msg->msg_name;
 	int err;
 	struct sockaddr_ax25 sax;
 	struct sk_buff *skb;
 	unsigned char *asmptr;
 	int size;
 
 	/* Netrom empty data frame has no meaning : don't send */
 	if (len == 0)
 		return 0;
 
 	if (msg->msg_flags & ~(MSG_DONTWAIT|MSG_EOR|MSG_CMSG_COMPAT))
 		return -EINVAL;
 
 	lock_sock(sk);
 	if (sock_flag(sk, SOCK_ZAPPED)) {
 		err = -EADDRNOTAVAIL;
 		goto out;
 	}
 
 	if (sk->sk_shutdown & SEND_SHUTDOWN) {
 		send_sig(SIGPIPE, current, 0);
 		err = -EPIPE;
 		goto out;
 	}
 
 	if (nr->device == NULL) {
 		err = -ENETUNREACH;
 		goto out;
 	}
 
 	if (usax) {
 		if (msg->msg_namelen < sizeof(sax)) {
 			err = -EINVAL;
 			goto out;
 		}
 		sax = *usax;
 		if (ax25cmp(&nr->dest_addr, &sax.sax25_call) != 0) {
 			err = -EISCONN;
 			goto out;
 		}
 		if (sax.sax25_family != AF_NETROM) {
 			err = -EINVAL;
 			goto out;
 		}
 	} else {
 		if (sk->sk_state != TCP_ESTABLISHED) {
 			err = -ENOTCONN;
 			goto out;
 		}
 		sax.sax25_family = AF_NETROM;
 		sax.sax25_call   = nr->dest_addr;
 	}
 
 	SOCK_DEBUG(sk, "NET/ROM: sendto: Addresses built.\n");
 
-	/* Build a packet */
+	/* Build a packet - the conventional user limit is 236 bytes. We can
+	   do ludicrously large NetROM frames but must not overflow */
+	if (len > 65536)
+		return -EMSGSIZE;
+
 	SOCK_DEBUG(sk, "NET/ROM: sendto: building packet.\n");
 	size = len + NR_NETWORK_LEN + NR_TRANSPORT_LEN;
 
 	if ((skb = sock_alloc_send_skb(sk, size, msg->msg_flags & MSG_DONTWAIT, &err)) == NULL)
 		goto out;
 
 	skb_reserve(skb, size - len);
 	skb_reset_transport_header(skb);
 
 	/*
 	 *	Push down the NET/ROM header
 	 */
 
 	asmptr = skb_push(skb, NR_TRANSPORT_LEN);
 	SOCK_DEBUG(sk, "Building NET/ROM Header.\n");
 
 	/* Build a NET/ROM Transport header */
 
 	*asmptr++ = nr->your_index;
 	*asmptr++ = nr->your_id;
 	*asmptr++ = 0;		/* To be filled in later */
 	*asmptr++ = 0;		/*      Ditto            */
 	*asmptr++ = NR_INFO;
 	SOCK_DEBUG(sk, "Built header.\n");
 
 	/*
 	 *	Put the data on the end
 	 */
 	skb_put(skb, len);
 
 	SOCK_DEBUG(sk, "NET/ROM: Appending user data\n");
 
 	/* User data follows immediately after the NET/ROM transport header */
 	if (memcpy_fromiovec(skb_transport_header(skb), msg->msg_iov, len)) {
 		kfree_skb(skb);
 		err = -EFAULT;
 		goto out;
 	}
 
 	SOCK_DEBUG(sk, "NET/ROM: Transmitting buffer\n");
 
 	if (sk->sk_state != TCP_ESTABLISHED) {
 		kfree_skb(skb);
 		err = -ENOTCONN;
 		goto out;
 	}
 
 	nr_output(sk, skb);	/* Shove it onto the queue */
 
 	err = len;
diff --git a/net/rose/af_rose.c b/net/rose/af_rose.c
index 6501396..0f36e8d 100644
--- a/net/rose/af_rose.c
+++ b/net/rose/af_rose.c
@@ -1063,175 +1063,179 @@ int rose_rx_call_request(struct sk_buff *skb, struct net_device *dev, struct ros
 static int rose_sendmsg(struct kiocb *iocb, struct socket *sock,
 			struct msghdr *msg, size_t len)
 {
 	struct sock *sk = sock->sk;
 	struct rose_sock *rose = rose_sk(sk);
 	struct sockaddr_rose *usrose = (struct sockaddr_rose *)msg->msg_name;
 	int err;
 	struct full_sockaddr_rose srose;
 	struct sk_buff *skb;
 	unsigned char *asmptr;
 	int n, size, qbit = 0;
 
 	/* ROSE empty frame has no meaning : don't send */
 	if (len == 0)
 		return 0;
 
 	if (msg->msg_flags & ~(MSG_DONTWAIT|MSG_EOR|MSG_CMSG_COMPAT))
 		return -EINVAL;
 
 	if (sock_flag(sk, SOCK_ZAPPED))
 		return -EADDRNOTAVAIL;
 
 	if (sk->sk_shutdown & SEND_SHUTDOWN) {
 		send_sig(SIGPIPE, current, 0);
 		return -EPIPE;
 	}
 
 	if (rose->neighbour == NULL || rose->device == NULL)
 		return -ENETUNREACH;
 
 	if (usrose != NULL) {
 		if (msg->msg_namelen != sizeof(struct sockaddr_rose) && msg->msg_namelen != sizeof(struct full_sockaddr_rose))
 			return -EINVAL;
 		memset(&srose, 0, sizeof(struct full_sockaddr_rose));
 		memcpy(&srose, usrose, msg->msg_namelen);
 		if (rosecmp(&rose->dest_addr, &srose.srose_addr) != 0 ||
 		    ax25cmp(&rose->dest_call, &srose.srose_call) != 0)
 			return -EISCONN;
 		if (srose.srose_ndigis != rose->dest_ndigis)
 			return -EISCONN;
 		if (srose.srose_ndigis == rose->dest_ndigis) {
 			for (n = 0 ; n < srose.srose_ndigis ; n++)
 				if (ax25cmp(&rose->dest_digis[n],
 					    &srose.srose_digis[n]))
 					return -EISCONN;
 		}
 		if (srose.srose_family != AF_ROSE)
 			return -EINVAL;
 	} else {
 		if (sk->sk_state != TCP_ESTABLISHED)
 			return -ENOTCONN;
 
 		srose.srose_family = AF_ROSE;
 		srose.srose_addr   = rose->dest_addr;
 		srose.srose_call   = rose->dest_call;
 		srose.srose_ndigis = rose->dest_ndigis;
 		for (n = 0 ; n < rose->dest_ndigis ; n++)
 			srose.srose_digis[n] = rose->dest_digis[n];
 	}
 
 	SOCK_DEBUG(sk, "ROSE: sendto: Addresses built.\n");
 
 	/* Build a packet */
 	SOCK_DEBUG(sk, "ROSE: sendto: building packet.\n");
+	/* Sanity check the packet size */
+	if (len > 65535)
+		return -EMSGSIZE;
+
 	size = len + AX25_BPQ_HEADER_LEN + AX25_MAX_HEADER_LEN + ROSE_MIN_LEN;
 
 	if ((skb = sock_alloc_send_skb(sk, size, msg->msg_flags & MSG_DONTWAIT, &err)) == NULL)
 		return err;
 
 	skb_reserve(skb, AX25_BPQ_HEADER_LEN + AX25_MAX_HEADER_LEN + ROSE_MIN_LEN);
 
 	/*
 	 *	Put the data on the end
 	 */
 	SOCK_DEBUG(sk, "ROSE: Appending user data\n");
 
 	skb_reset_transport_header(skb);
 	skb_put(skb, len);
 
 	err = memcpy_fromiovec(skb_transport_header(skb), msg->msg_iov, len);
 	if (err) {
 		kfree_skb(skb);
 		return err;
 	}
 
 	/*
 	 *	If the Q BIT Include socket option is in force, the first
 	 *	byte of the user data is the logical value of the Q Bit.
 	 */
 	if (rose->qbitincl) {
 		qbit = skb->data[0];
 		skb_pull(skb, 1);
 	}
 
 	/*
 	 *	Push down the ROSE header
 	 */
 	asmptr = skb_push(skb, ROSE_MIN_LEN);
 
 	SOCK_DEBUG(sk, "ROSE: Building Network Header.\n");
 
 	/* Build a ROSE Network header */
 	asmptr[0] = ((rose->lci >> 8) & 0x0F) | ROSE_GFI;
 	asmptr[1] = (rose->lci >> 0) & 0xFF;
 	asmptr[2] = ROSE_DATA;
 
 	if (qbit)
 		asmptr[0] |= ROSE_Q_BIT;
 
 	SOCK_DEBUG(sk, "ROSE: Built header.\n");
 
 	SOCK_DEBUG(sk, "ROSE: Transmitting buffer\n");
 
 	if (sk->sk_state != TCP_ESTABLISHED) {
 		kfree_skb(skb);
 		return -ENOTCONN;
 	}
 
 #ifdef M_BIT
 #define ROSE_PACLEN (256-ROSE_MIN_LEN)
 	if (skb->len - ROSE_MIN_LEN > ROSE_PACLEN) {
 		unsigned char header[ROSE_MIN_LEN];
 		struct sk_buff *skbn;
 		int frontlen;
 		int lg;
 
 		/* Save a copy of the Header */
 		skb_copy_from_linear_data(skb, header, ROSE_MIN_LEN);
 		skb_pull(skb, ROSE_MIN_LEN);
 
 		frontlen = skb_headroom(skb);
 
 		while (skb->len > 0) {
 			if ((skbn = sock_alloc_send_skb(sk, frontlen + ROSE_PACLEN, 0, &err)) == NULL) {
 				kfree_skb(skb);
 				return err;
 			}
 
 			skbn->sk   = sk;
 			skbn->free = 1;
 			skbn->arp  = 1;
 
 			skb_reserve(skbn, frontlen);
 
 			lg = (ROSE_PACLEN > skb->len) ? skb->len : ROSE_PACLEN;
 
 			/* Copy the user data */
 			skb_copy_from_linear_data(skb, skb_put(skbn, lg), lg);
 			skb_pull(skb, lg);
 
 			/* Duplicate the Header */
 			skb_push(skbn, ROSE_MIN_LEN);
 			skb_copy_to_linear_data(skbn, header, ROSE_MIN_LEN);
 
 			if (skb->len > 0)
 				skbn->data[2] |= M_BIT;
 
 			skb_queue_tail(&sk->sk_write_queue, skbn); /* Throw it on the queue */
 		}
 
 		skb->free = 1;
 		kfree_skb(skb);
 	} else {
 		skb_queue_tail(&sk->sk_write_queue, skb);		/* Throw it on the queue */
 	}
 #else
 	skb_queue_tail(&sk->sk_write_queue, skb);	/* Shove it onto the queue */
 #endif
 
 	rose_kick(sk);
 
 	return len;
 }
 
 
diff --git a/net/x25/af_x25.c b/net/x25/af_x25.c
index 9ca17b1..ed80af8 100644
--- a/net/x25/af_x25.c
+++ b/net/x25/af_x25.c
@@ -979,170 +979,176 @@ out_clear_request:
 static int x25_sendmsg(struct kiocb *iocb, struct socket *sock,
 		       struct msghdr *msg, size_t len)
 {
 	struct sock *sk = sock->sk;
 	struct x25_sock *x25 = x25_sk(sk);
 	struct sockaddr_x25 *usx25 = (struct sockaddr_x25 *)msg->msg_name;
 	struct sockaddr_x25 sx25;
 	struct sk_buff *skb;
 	unsigned char *asmptr;
 	int noblock = msg->msg_flags & MSG_DONTWAIT;
 	size_t size;
 	int qbit = 0, rc = -EINVAL;
 
 	if (msg->msg_flags & ~(MSG_DONTWAIT|MSG_OOB|MSG_EOR|MSG_CMSG_COMPAT))
 		goto out;
 
 	/* we currently don't support segmented records at the user interface */
 	if (!(msg->msg_flags & (MSG_EOR|MSG_OOB)))
 		goto out;
 
 	rc = -EADDRNOTAVAIL;
 	if (sock_flag(sk, SOCK_ZAPPED))
 		goto out;
 
 	rc = -EPIPE;
 	if (sk->sk_shutdown & SEND_SHUTDOWN) {
 		send_sig(SIGPIPE, current, 0);
 		goto out;
 	}
 
 	rc = -ENETUNREACH;
 	if (!x25->neighbour)
 		goto out;
 
 	if (usx25) {
 		rc = -EINVAL;
 		if (msg->msg_namelen < sizeof(sx25))
 			goto out;
 		memcpy(&sx25, usx25, sizeof(sx25));
 		rc = -EISCONN;
 		if (strcmp(x25->dest_addr.x25_addr, sx25.sx25_addr.x25_addr))
 			goto out;
 		rc = -EINVAL;
 		if (sx25.sx25_family != AF_X25)
 			goto out;
 	} else {
 		/*
 		 *	FIXME 1003.1g - if the socket is like this because
 		 *	it has become closed (not started closed) we ought
 		 *	to SIGPIPE, EPIPE;
 		 */
 		rc = -ENOTCONN;
 		if (sk->sk_state != TCP_ESTABLISHED)
 			goto out;
 
 		sx25.sx25_family = AF_X25;
 		sx25.sx25_addr   = x25->dest_addr;
 	}
 
+	/* Sanity check the packet size */
+	if (len > 65535) {
+		rc = -EMSGSIZE;
+		goto out;
+	}
+
 	SOCK_DEBUG(sk, "x25_sendmsg: sendto: Addresses built.\n");
 
 	/* Build a packet */
 	SOCK_DEBUG(sk, "x25_sendmsg: sendto: building packet.\n");
 
 	if ((msg->msg_flags & MSG_OOB) && len > 32)
 		len = 32;
 
 	size = len + X25_MAX_L2_LEN + X25_EXT_MIN_LEN;
 
 	skb = sock_alloc_send_skb(sk, size, noblock, &rc);
 	if (!skb)
 		goto out;
 	X25_SKB_CB(skb)->flags = msg->msg_flags;
 
 	skb_reserve(skb, X25_MAX_L2_LEN + X25_EXT_MIN_LEN);
 
 	/*
 	 *	Put the data on the end
 	 */
 	SOCK_DEBUG(sk, "x25_sendmsg: Copying user data\n");
 
 	skb_reset_transport_header(skb);
 	skb_put(skb, len);
 
 	rc = memcpy_fromiovec(skb_transport_header(skb), msg->msg_iov, len);
 	if (rc)
 		goto out_kfree_skb;
 
 	/*
 	 *	If the Q BIT Include socket option is in force, the first
 	 *	byte of the user data is the logical value of the Q Bit.
 	 */
 	if (x25->qbitincl) {
 		qbit = skb->data[0];
 		skb_pull(skb, 1);
 	}
 
 	/*
 	 *	Push down the X.25 header
 	 */
 	SOCK_DEBUG(sk, "x25_sendmsg: Building X.25 Header.\n");
 
 	if (msg->msg_flags & MSG_OOB) {
 		if (x25->neighbour->extended) {
 			asmptr    = skb_push(skb, X25_STD_MIN_LEN);
 			*asmptr++ = ((x25->lci >> 8) & 0x0F) | X25_GFI_EXTSEQ;
 			*asmptr++ = (x25->lci >> 0) & 0xFF;
 			*asmptr++ = X25_INTERRUPT;
 		} else {
 			asmptr    = skb_push(skb, X25_STD_MIN_LEN);
 			*asmptr++ = ((x25->lci >> 8) & 0x0F) | X25_GFI_STDSEQ;
 			*asmptr++ = (x25->lci >> 0) & 0xFF;
 			*asmptr++ = X25_INTERRUPT;
 		}
 	} else {
 		if (x25->neighbour->extended) {
 			/* Build an Extended X.25 header */
 			asmptr    = skb_push(skb, X25_EXT_MIN_LEN);
 			*asmptr++ = ((x25->lci >> 8) & 0x0F) | X25_GFI_EXTSEQ;
 			*asmptr++ = (x25->lci >> 0) & 0xFF;
 			*asmptr++ = X25_DATA;
 			*asmptr++ = X25_DATA;
 		} else {
 			/* Build an Standard X.25 header */
 			asmptr    = skb_push(skb, X25_STD_MIN_LEN);
 			*asmptr++ = ((x25->lci >> 8) & 0x0F) | X25_GFI_STDSEQ;
 			*asmptr++ = (x25->lci >> 0) & 0xFF;
 			*asmptr++ = X25_DATA;
 		}
 
 		if (qbit)
 			skb->data[0] |= X25_Q_BIT;
 	}
 
 	SOCK_DEBUG(sk, "x25_sendmsg: Built header.\n");
 	SOCK_DEBUG(sk, "x25_sendmsg: Transmitting buffer\n");
 
 	rc = -ENOTCONN;
 	if (sk->sk_state != TCP_ESTABLISHED)
 		goto out_kfree_skb;
 
 	if (msg->msg_flags & MSG_OOB)
 		skb_queue_tail(&x25->interrupt_out_queue, skb);
 	else {
 		rc = x25_output(sk, skb);
 		len = rc;
 		if (rc < 0)
 			kfree_skb(skb);
 		else if (x25->qbitincl)
 			len++;
 	}
 
 	/*
 	 * lock_sock() is currently only used to serialize this x25_kick()
 	 * against input-driven x25_kick() calls. It currently only blocks
 	 * incoming packets for this socket and does not protect against
 	 * any other socket state changes and is not called from anywhere
 	 * else. As x25_kick() cannot block and as long as all socket
 	 * operations are BKL-wrapped, we don't need take to care about
 	 * purging the backlog queue in x25_release().
 	 *
 	 * Using lock_sock() to protect all socket operations entirely
 	 * (and making the whole x25 stack SMP aware) unfortunately would
 	 * require major changes to {send,recv}msg and skb allocation methods.
 	 * -> 2.5 ;)
 	 */
 	lock_sock(sk);
 	x25_kick(sk);
 	release_sock(sk);
 	rc = len;
